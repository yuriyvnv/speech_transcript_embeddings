2025-06-17 22:17:24,646 - INFO - Training with parameters:
2025-06-17 22:17:24,647 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 22:17:24,647 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 22:17:24,647 - INFO -   Freeze encoders: partial
2025-06-17 22:17:24,647 - INFO -   Text layers to unfreeze: 5
2025-06-17 22:17:24,647 - INFO -   Audio layers to unfreeze: 5
2025-06-17 22:17:24,647 - INFO -   Use cross-modal attention: True
2025-06-17 22:17:24,647 - INFO -   Use attentive pooling: True
2025-06-17 22:17:24,647 - INFO -   Use word-level alignment: False
2025-06-17 22:17:24,647 - INFO -   Batch size: 8
2025-06-17 22:17:24,647 - INFO -   Gradient accumulation steps: 16
2025-06-17 22:17:24,647 - INFO -   Effective batch size: 128
2025-06-17 22:17:24,647 - INFO -   Mixed precision training: False
2025-06-17 22:17:24,648 - INFO -   Learning rate: 3e-05
2025-06-17 22:17:24,648 - INFO -   Temperature: 0.1
2025-06-17 22:17:24,648 - INFO -   Projection dimension: 1024
2025-06-17 22:17:24,648 - INFO -   Training samples: 21968
2025-06-17 22:17:24,648 - INFO -   Validation samples: 9464
2025-06-17 22:17:24,648 - INFO -   Test samples: 9467
2025-06-17 22:17:24,648 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 22:17:24,648 - INFO - Loading tokenizer and feature extractor...
2025-06-17 22:17:25,128 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 22:17:25,128 - INFO - Creating datasets...
2025-06-17 22:17:25,130 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 22:17:25,132 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 22:17:25,134 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 22:17:25,135 - INFO - Creating data loaders...
2025-06-17 22:17:25,136 - INFO - Checking a sample batch...
2025-06-17 22:17:32,912 - INFO -   input_ids_pos: torch.Size([8, 256])
2025-06-17 22:17:32,913 - INFO -   attention_mask_pos: torch.Size([8, 256])
2025-06-17 22:17:32,913 - INFO -   input_ids_neg: torch.Size([8, 256])
2025-06-17 22:17:32,913 - INFO -   attention_mask_neg: torch.Size([8, 256])
2025-06-17 22:17:32,913 - INFO -   input_values: torch.Size([8, 328, 160])
2025-06-17 22:17:32,914 - INFO -   attention_mask_audio: torch.Size([8, 328])
2025-06-17 22:17:32,914 - INFO -   is_corrupted: torch.Size([8])
2025-06-17 22:17:32,914 - INFO - Initializing model...
2025-06-17 22:17:36,236 - INFO - Partial freezing: unfreezing last 5 text layers and 5 audio layers
2025-06-17 22:17:36,237 - INFO - Unfreezing text encoder layer 19
2025-06-17 22:17:36,237 - INFO - Unfreezing text encoder layer 20
2025-06-17 22:17:36,237 - INFO - Unfreezing text encoder layer 21
2025-06-17 22:17:36,237 - INFO - Unfreezing text encoder layer 22
2025-06-17 22:17:36,237 - INFO - Unfreezing text encoder layer 23
2025-06-17 22:17:36,242 - INFO - Unfreezing audio encoder layer 19
2025-06-17 22:17:36,242 - INFO - Unfreezing audio encoder layer 20
2025-06-17 22:17:36,242 - INFO - Unfreezing audio encoder layer 21
2025-06-17 22:17:36,242 - INFO - Unfreezing audio encoder layer 22
2025-06-17 22:17:36,243 - INFO - Unfreezing audio encoder layer 23
2025-06-17 22:17:36,543 - INFO - Model initialized with 259,145,858 trainable parameters out of 957,899,586 total
2025-06-17 22:17:38,213 - INFO - Using discriminative learning rates: encoder_lr=3e-06, main_lr=3e-05
2025-06-17 22:17:38,213 - INFO - Encoder parameters: 252, Non-encoder parameters: 44
2025-06-17 22:17:38,214 - INFO - Scheduler setup:
2025-06-17 22:17:38,214 - INFO -   Batches per epoch: 2746
2025-06-17 22:17:38,214 - INFO -   Accumulation steps: 16
2025-06-17 22:17:38,214 - INFO -   Optimizer steps per epoch: 172
2025-06-17 22:17:38,214 - INFO -   Total optimizer steps: 10320
2025-06-17 22:17:38,214 - INFO -   Warmup steps: 500
2025-06-17 22:17:38,214 - INFO - Validating gradient accumulation setup...
2025-06-17 22:17:38,215 - INFO - Validating gradient accumulation with 16 steps...
2025-06-17 22:17:47,133 - WARNING - Not enough test batches (10) for accumulation_steps (16)
2025-06-17 22:17:47,134 - INFO - Starting training for 60 epochs
2025-06-17 23:00:39,953 - INFO - Training with parameters:
2025-06-17 23:00:39,953 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:00:39,953 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:00:39,953 - INFO -   Freeze encoders: partial
2025-06-17 23:00:39,953 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:00:39,953 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:00:39,953 - INFO -   Use cross-modal attention: True
2025-06-17 23:00:39,954 - INFO -   Use attentive pooling: True
2025-06-17 23:00:39,954 - INFO -   Use word-level alignment: False
2025-06-17 23:00:39,954 - INFO -   Batch size: 8
2025-06-17 23:00:39,954 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:00:39,954 - INFO -   Effective batch size: 128
2025-06-17 23:00:39,954 - INFO -   Mixed precision training: False
2025-06-17 23:00:39,954 - INFO -   Learning rate: 3e-05
2025-06-17 23:00:39,954 - INFO -   Temperature: 0.1
2025-06-17 23:00:39,954 - INFO -   Projection dimension: 1024
2025-06-17 23:00:39,954 - INFO -   Training samples: 21968
2025-06-17 23:00:39,954 - INFO -   Validation samples: 9464
2025-06-17 23:00:39,954 - INFO -   Test samples: 9467
2025-06-17 23:00:39,954 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:00:39,954 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:00:40,699 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:00:40,699 - INFO - Creating datasets...
2025-06-17 23:00:40,701 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:00:40,702 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:00:40,703 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:00:40,703 - INFO - Creating data loaders...
2025-06-17 23:00:40,704 - INFO - Checking a sample batch...
2025-06-17 23:00:41,067 - WARNING - Error checking sample batch: Caught ImportError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 153, in decode_example
    import librosa
ModuleNotFoundError: No module named 'librosa'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 156, in decode_example
    raise ImportError("To support decoding audio files, please install 'librosa' and 'soundfile'.") from err
ImportError: To support decoding audio files, please install 'librosa' and 'soundfile'.

2025-06-17 23:00:41,068 - INFO - Initializing model...
2025-06-17 23:01:11,192 - INFO - Training with parameters:
2025-06-17 23:01:11,192 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:01:11,192 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:01:11,192 - INFO -   Freeze encoders: partial
2025-06-17 23:01:11,192 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:01:11,192 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:01:11,192 - INFO -   Use cross-modal attention: True
2025-06-17 23:01:11,193 - INFO -   Use attentive pooling: True
2025-06-17 23:01:11,193 - INFO -   Use word-level alignment: False
2025-06-17 23:01:11,193 - INFO -   Batch size: 8
2025-06-17 23:01:11,193 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:01:11,193 - INFO -   Effective batch size: 128
2025-06-17 23:01:11,193 - INFO -   Mixed precision training: False
2025-06-17 23:01:11,193 - INFO -   Learning rate: 3e-05
2025-06-17 23:01:11,193 - INFO -   Temperature: 0.1
2025-06-17 23:01:11,193 - INFO -   Projection dimension: 1024
2025-06-17 23:01:11,193 - INFO -   Training samples: 21968
2025-06-17 23:01:11,193 - INFO -   Validation samples: 9464
2025-06-17 23:01:11,193 - INFO -   Test samples: 9467
2025-06-17 23:01:11,193 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:01:11,193 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:01:11,865 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:01:11,865 - INFO - Creating datasets...
2025-06-17 23:01:11,866 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:01:11,867 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:01:11,868 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:01:11,869 - INFO - Creating data loaders...
2025-06-17 23:01:11,869 - INFO - Checking a sample batch...
2025-06-17 23:01:12,255 - WARNING - Error checking sample batch: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 165, in decode_example
    raise RuntimeError(
RuntimeError: Decoding 'mp3' files requires system library 'libsndfile'>=1.1.0, You can try to update `soundfile` python library: `pip install "soundfile>=0.12.1"`. 

2025-06-17 23:01:12,255 - INFO - Initializing model...
2025-06-17 23:01:15,525 - INFO - Partial freezing: unfreezing last 5 text layers and 5 audio layers
2025-06-17 23:01:15,527 - INFO - Unfreezing text encoder layer 19
2025-06-17 23:01:15,527 - INFO - Unfreezing text encoder layer 20
2025-06-17 23:01:15,527 - INFO - Unfreezing text encoder layer 21
2025-06-17 23:01:15,527 - INFO - Unfreezing text encoder layer 22
2025-06-17 23:01:15,527 - INFO - Unfreezing text encoder layer 23
2025-06-17 23:01:15,529 - INFO - Unfreezing audio encoder layer 19
2025-06-17 23:01:15,529 - INFO - Unfreezing audio encoder layer 20
2025-06-17 23:01:15,529 - INFO - Unfreezing audio encoder layer 21
2025-06-17 23:01:15,529 - INFO - Unfreezing audio encoder layer 22
2025-06-17 23:01:15,529 - INFO - Unfreezing audio encoder layer 23
2025-06-17 23:01:15,851 - INFO - Model initialized with 259,145,858 trainable parameters out of 957,899,586 total
2025-06-17 23:01:17,560 - INFO - Using discriminative learning rates: encoder_lr=3e-06, main_lr=3e-05
2025-06-17 23:01:17,560 - INFO - Encoder parameters: 252, Non-encoder parameters: 44
2025-06-17 23:01:17,561 - INFO - Scheduler setup:
2025-06-17 23:01:17,561 - INFO -   Batches per epoch: 2746
2025-06-17 23:01:17,561 - INFO -   Accumulation steps: 16
2025-06-17 23:01:17,561 - INFO -   Optimizer steps per epoch: 172
2025-06-17 23:01:17,561 - INFO -   Total optimizer steps: 5160
2025-06-17 23:01:17,561 - INFO -   Warmup steps: 500
2025-06-17 23:01:17,561 - INFO - Validating gradient accumulation setup...
2025-06-17 23:01:17,561 - INFO - Validating gradient accumulation with 16 steps...
2025-06-17 23:01:17,755 - WARNING - Gradient accumulation validation failed: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 165, in decode_example
    raise RuntimeError(
RuntimeError: Decoding 'mp3' files requires system library 'libsndfile'>=1.1.0, You can try to update `soundfile` python library: `pip install "soundfile>=0.12.1"`. 

2025-06-17 23:01:17,762 - WARNING - Continuing with training anyway...
2025-06-17 23:01:17,763 - INFO - Starting training for 30 epochs
2025-06-17 23:01:51,954 - INFO - Training with parameters:
2025-06-17 23:01:51,954 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:01:51,954 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:01:51,954 - INFO -   Freeze encoders: partial
2025-06-17 23:01:51,954 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:01:51,954 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:01:51,954 - INFO -   Use cross-modal attention: True
2025-06-17 23:01:51,954 - INFO -   Use attentive pooling: True
2025-06-17 23:01:51,955 - INFO -   Use word-level alignment: False
2025-06-17 23:01:51,955 - INFO -   Batch size: 8
2025-06-17 23:01:51,955 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:01:51,955 - INFO -   Effective batch size: 128
2025-06-17 23:01:51,955 - INFO -   Mixed precision training: False
2025-06-17 23:01:51,955 - INFO -   Learning rate: 3e-05
2025-06-17 23:01:51,955 - INFO -   Temperature: 0.1
2025-06-17 23:01:51,955 - INFO -   Projection dimension: 1024
2025-06-17 23:01:51,955 - INFO -   Training samples: 21968
2025-06-17 23:01:51,955 - INFO -   Validation samples: 9464
2025-06-17 23:01:51,955 - INFO -   Test samples: 9467
2025-06-17 23:01:51,955 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:01:51,955 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:01:52,907 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:01:52,907 - INFO - Creating datasets...
2025-06-17 23:01:52,909 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:01:52,910 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:01:52,911 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:01:52,911 - INFO - Creating data loaders...
2025-06-17 23:01:52,912 - INFO - Checking a sample batch...
2025-06-17 23:01:53,267 - WARNING - Error checking sample batch: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 165, in decode_example
    raise RuntimeError(
RuntimeError: Decoding 'mp3' files requires system library 'libsndfile'>=1.1.0, You can try to update `soundfile` python library: `pip install "soundfile>=0.12.1"`. 

2025-06-17 23:01:53,268 - INFO - Initializing model...
2025-06-17 23:01:56,977 - INFO - Partial freezing: unfreezing last 5 text layers and 5 audio layers
2025-06-17 23:01:56,981 - INFO - Unfreezing text encoder layer 19
2025-06-17 23:01:56,981 - INFO - Unfreezing text encoder layer 20
2025-06-17 23:01:56,981 - INFO - Unfreezing text encoder layer 21
2025-06-17 23:01:56,981 - INFO - Unfreezing text encoder layer 22
2025-06-17 23:01:56,981 - INFO - Unfreezing text encoder layer 23
2025-06-17 23:01:56,986 - INFO - Unfreezing audio encoder layer 19
2025-06-17 23:01:56,986 - INFO - Unfreezing audio encoder layer 20
2025-06-17 23:01:56,986 - INFO - Unfreezing audio encoder layer 21
2025-06-17 23:01:56,986 - INFO - Unfreezing audio encoder layer 22
2025-06-17 23:01:56,986 - INFO - Unfreezing audio encoder layer 23
2025-06-17 23:01:57,322 - INFO - Model initialized with 259,145,858 trainable parameters out of 957,899,586 total
2025-06-17 23:02:44,491 - INFO - Training with parameters:
2025-06-17 23:02:44,491 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:02:44,491 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:02:44,491 - INFO -   Freeze encoders: partial
2025-06-17 23:02:44,491 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:02:44,491 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:02:44,491 - INFO -   Use cross-modal attention: True
2025-06-17 23:02:44,492 - INFO -   Use attentive pooling: True
2025-06-17 23:02:44,492 - INFO -   Use word-level alignment: False
2025-06-17 23:02:44,492 - INFO -   Batch size: 8
2025-06-17 23:02:44,492 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:02:44,492 - INFO -   Effective batch size: 128
2025-06-17 23:02:44,492 - INFO -   Mixed precision training: False
2025-06-17 23:02:44,492 - INFO -   Learning rate: 3e-05
2025-06-17 23:02:44,492 - INFO -   Temperature: 0.1
2025-06-17 23:02:44,492 - INFO -   Projection dimension: 1024
2025-06-17 23:02:44,492 - INFO -   Training samples: 21968
2025-06-17 23:02:44,492 - INFO -   Validation samples: 9464
2025-06-17 23:02:44,492 - INFO -   Test samples: 9467
2025-06-17 23:02:44,492 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:02:44,492 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:02:45,134 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:02:45,135 - INFO - Creating datasets...
2025-06-17 23:02:45,136 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:02:45,137 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:02:45,139 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:02:45,139 - INFO - Creating data loaders...
2025-06-17 23:02:45,140 - INFO - Checking a sample batch...
2025-06-17 23:02:45,547 - WARNING - Error checking sample batch: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 165, in decode_example
    raise RuntimeError(
RuntimeError: Decoding 'mp3' files requires system library 'libsndfile'>=1.1.0, You can try to update `soundfile` python library: `pip install "soundfile>=0.12.1"`. 

2025-06-17 23:02:45,547 - INFO - Initializing model...
2025-06-17 23:06:49,795 - INFO - Training with parameters:
2025-06-17 23:06:49,795 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:06:49,795 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:06:49,795 - INFO -   Freeze encoders: partial
2025-06-17 23:06:49,795 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:06:49,795 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:06:49,796 - INFO -   Use cross-modal attention: True
2025-06-17 23:06:49,796 - INFO -   Use attentive pooling: True
2025-06-17 23:06:49,796 - INFO -   Use word-level alignment: False
2025-06-17 23:06:49,796 - INFO -   Batch size: 8
2025-06-17 23:06:49,796 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:06:49,796 - INFO -   Effective batch size: 128
2025-06-17 23:06:49,796 - INFO -   Mixed precision training: False
2025-06-17 23:06:49,796 - INFO -   Learning rate: 3e-05
2025-06-17 23:06:49,796 - INFO -   Temperature: 0.1
2025-06-17 23:06:49,796 - INFO -   Projection dimension: 1024
2025-06-17 23:06:49,797 - INFO -   Training samples: 21968
2025-06-17 23:06:49,797 - INFO -   Validation samples: 9464
2025-06-17 23:06:49,797 - INFO -   Test samples: 9467
2025-06-17 23:06:49,797 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:06:49,797 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:06:50,681 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:06:50,681 - INFO - Creating datasets...
2025-06-17 23:06:50,683 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:06:50,684 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:06:50,685 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:06:50,685 - INFO - Creating data loaders...
2025-06-17 23:06:50,686 - INFO - Checking a sample batch...
2025-06-17 23:06:51,144 - WARNING - Error checking sample batch: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 165, in decode_example
    raise RuntimeError(
RuntimeError: Decoding 'mp3' files requires system library 'libsndfile'>=1.1.0, You can try to update `soundfile` python library: `pip install "soundfile>=0.12.1"`. 

2025-06-17 23:06:51,145 - INFO - Initializing model...
2025-06-17 23:06:54,753 - INFO - Partial freezing: unfreezing last 5 text layers and 5 audio layers
2025-06-17 23:06:54,755 - INFO - Unfreezing text encoder layer 19
2025-06-17 23:06:54,755 - INFO - Unfreezing text encoder layer 20
2025-06-17 23:06:54,755 - INFO - Unfreezing text encoder layer 21
2025-06-17 23:06:54,755 - INFO - Unfreezing text encoder layer 22
2025-06-17 23:06:54,755 - INFO - Unfreezing text encoder layer 23
2025-06-17 23:06:54,757 - INFO - Unfreezing audio encoder layer 19
2025-06-17 23:06:54,757 - INFO - Unfreezing audio encoder layer 20
2025-06-17 23:06:54,757 - INFO - Unfreezing audio encoder layer 21
2025-06-17 23:06:54,757 - INFO - Unfreezing audio encoder layer 22
2025-06-17 23:06:54,757 - INFO - Unfreezing audio encoder layer 23
2025-06-17 23:06:55,036 - INFO - Model initialized with 259,145,858 trainable parameters out of 957,899,586 total
2025-06-17 23:06:56,664 - INFO - Using discriminative learning rates: encoder_lr=3e-06, main_lr=3e-05
2025-06-17 23:06:56,664 - INFO - Encoder parameters: 252, Non-encoder parameters: 44
2025-06-17 23:06:56,664 - INFO - Scheduler setup:
2025-06-17 23:06:56,664 - INFO -   Batches per epoch: 2746
2025-06-17 23:06:56,664 - INFO -   Accumulation steps: 16
2025-06-17 23:06:56,664 - INFO -   Optimizer steps per epoch: 172
2025-06-17 23:06:56,664 - INFO -   Total optimizer steps: 5160
2025-06-17 23:06:56,665 - INFO -   Warmup steps: 500
2025-06-17 23:06:56,665 - INFO - Validating gradient accumulation setup...
2025-06-17 23:06:56,665 - INFO - Validating gradient accumulation with 16 steps...
2025-06-17 23:06:56,866 - WARNING - Gradient accumulation validation failed: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 165, in decode_example
    raise RuntimeError(
RuntimeError: Decoding 'mp3' files requires system library 'libsndfile'>=1.1.0, You can try to update `soundfile` python library: `pip install "soundfile>=0.12.1"`. 

2025-06-17 23:06:56,867 - WARNING - Continuing with training anyway...
2025-06-17 23:06:56,868 - INFO - Starting training for 30 epochs
2025-06-17 23:06:57,393 - ERROR - Error in epoch 1: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 165, in decode_example
    raise RuntimeError(
RuntimeError: Decoding 'mp3' files requires system library 'libsndfile'>=1.1.0, You can try to update `soundfile` python library: `pip install "soundfile>=0.12.1"`. 

2025-06-17 23:06:57,968 - ERROR - Error in epoch 2: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 165, in decode_example
    raise RuntimeError(
RuntimeError: Decoding 'mp3' files requires system library 'libsndfile'>=1.1.0, You can try to update `soundfile` python library: `pip install "soundfile>=0.12.1"`. 

2025-06-17 23:06:58,513 - ERROR - Error in epoch 3: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 165, in decode_example
    raise RuntimeError(
RuntimeError: Decoding 'mp3' files requires system library 'libsndfile'>=1.1.0, You can try to update `soundfile` python library: `pip install "soundfile>=0.12.1"`. 

2025-06-17 23:06:59,075 - ERROR - Error in epoch 4: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 165, in decode_example
    raise RuntimeError(
RuntimeError: Decoding 'mp3' files requires system library 'libsndfile'>=1.1.0, You can try to update `soundfile` python library: `pip install "soundfile>=0.12.1"`. 

2025-06-17 23:07:56,518 - INFO - Training with parameters:
2025-06-17 23:07:56,518 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:07:56,518 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:07:56,518 - INFO -   Freeze encoders: partial
2025-06-17 23:07:56,518 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:07:56,518 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:07:56,518 - INFO -   Use cross-modal attention: True
2025-06-17 23:07:56,518 - INFO -   Use attentive pooling: True
2025-06-17 23:07:56,518 - INFO -   Use word-level alignment: False
2025-06-17 23:07:56,518 - INFO -   Batch size: 8
2025-06-17 23:07:56,518 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:07:56,518 - INFO -   Effective batch size: 128
2025-06-17 23:07:56,519 - INFO -   Mixed precision training: False
2025-06-17 23:07:56,519 - INFO -   Learning rate: 3e-05
2025-06-17 23:07:56,519 - INFO -   Temperature: 0.1
2025-06-17 23:07:56,519 - INFO -   Projection dimension: 1024
2025-06-17 23:07:56,519 - INFO -   Training samples: 21968
2025-06-17 23:07:56,519 - INFO -   Validation samples: 9464
2025-06-17 23:07:56,519 - INFO -   Test samples: 9467
2025-06-17 23:07:56,519 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:07:56,519 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:07:57,193 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:07:57,194 - INFO - Creating datasets...
2025-06-17 23:07:57,195 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:07:57,196 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:07:57,197 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:07:57,197 - INFO - Creating data loaders...
2025-06-17 23:07:57,198 - INFO - Checking a sample batch...
2025-06-17 23:07:57,556 - WARNING - Error checking sample batch: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 165, in decode_example
    raise RuntimeError(
RuntimeError: Decoding 'mp3' files requires system library 'libsndfile'>=1.1.0, You can try to update `soundfile` python library: `pip install "soundfile>=0.12.1"`. 

2025-06-17 23:07:57,557 - INFO - Initializing model...
2025-06-17 23:12:08,030 - INFO - Training with parameters:
2025-06-17 23:12:08,030 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:12:08,030 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:12:08,030 - INFO -   Freeze encoders: partial
2025-06-17 23:12:08,031 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:12:08,031 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:12:08,031 - INFO -   Use cross-modal attention: True
2025-06-17 23:12:08,031 - INFO -   Use attentive pooling: True
2025-06-17 23:12:08,031 - INFO -   Use word-level alignment: False
2025-06-17 23:12:08,031 - INFO -   Batch size: 8
2025-06-17 23:12:08,031 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:12:08,031 - INFO -   Effective batch size: 128
2025-06-17 23:12:08,031 - INFO -   Mixed precision training: False
2025-06-17 23:12:08,031 - INFO -   Learning rate: 3e-05
2025-06-17 23:12:08,031 - INFO -   Temperature: 0.1
2025-06-17 23:12:08,031 - INFO -   Projection dimension: 1024
2025-06-17 23:12:08,031 - INFO -   Training samples: 21968
2025-06-17 23:12:08,031 - INFO -   Validation samples: 9464
2025-06-17 23:12:08,031 - INFO -   Test samples: 9467
2025-06-17 23:12:08,031 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:12:08,031 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:12:09,048 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:12:09,048 - INFO - Creating datasets...
2025-06-17 23:12:09,049 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:12:09,051 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:12:09,052 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:12:09,052 - INFO - Creating data loaders...
2025-06-17 23:12:09,053 - INFO - Checking a sample batch...
2025-06-17 23:12:09,394 - WARNING - Error checking sample batch: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 165, in decode_example
    raise RuntimeError(
RuntimeError: Decoding 'mp3' files requires system library 'libsndfile'>=1.1.0, You can try to update `soundfile` python library: `pip install "soundfile>=0.12.1"`. 

2025-06-17 23:12:09,395 - INFO - Initializing model...
2025-06-17 23:16:08,269 - INFO - Training with parameters:
2025-06-17 23:16:08,269 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:16:08,269 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:16:08,269 - INFO -   Freeze encoders: partial
2025-06-17 23:16:08,269 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:16:08,269 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:16:08,269 - INFO -   Use cross-modal attention: True
2025-06-17 23:16:08,269 - INFO -   Use attentive pooling: True
2025-06-17 23:16:08,270 - INFO -   Use word-level alignment: False
2025-06-17 23:16:08,270 - INFO -   Batch size: 8
2025-06-17 23:16:08,270 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:16:08,270 - INFO -   Effective batch size: 128
2025-06-17 23:16:08,270 - INFO -   Mixed precision training: False
2025-06-17 23:16:08,270 - INFO -   Learning rate: 3e-05
2025-06-17 23:16:08,270 - INFO -   Temperature: 0.1
2025-06-17 23:16:08,270 - INFO -   Projection dimension: 1024
2025-06-17 23:16:08,270 - INFO -   Training samples: 21968
2025-06-17 23:16:08,270 - INFO -   Validation samples: 9464
2025-06-17 23:16:08,270 - INFO -   Test samples: 9467
2025-06-17 23:16:08,270 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:16:08,270 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:21:10,004 - INFO - Training with parameters:
2025-06-17 23:21:10,004 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:21:10,004 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:21:10,004 - INFO -   Freeze encoders: partial
2025-06-17 23:21:10,004 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:21:10,005 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:21:10,005 - INFO -   Use cross-modal attention: True
2025-06-17 23:21:10,005 - INFO -   Use attentive pooling: True
2025-06-17 23:21:10,005 - INFO -   Use word-level alignment: False
2025-06-17 23:21:10,005 - INFO -   Batch size: 8
2025-06-17 23:21:10,005 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:21:10,005 - INFO -   Effective batch size: 128
2025-06-17 23:21:10,005 - INFO -   Mixed precision training: False
2025-06-17 23:21:10,005 - INFO -   Learning rate: 3e-05
2025-06-17 23:21:10,005 - INFO -   Temperature: 0.1
2025-06-17 23:21:10,005 - INFO -   Projection dimension: 1024
2025-06-17 23:21:10,005 - INFO -   Training samples: 21968
2025-06-17 23:21:10,005 - INFO -   Validation samples: 9464
2025-06-17 23:21:10,005 - INFO -   Test samples: 9467
2025-06-17 23:21:10,005 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:21:10,005 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:21:10,682 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:21:10,682 - INFO - Creating datasets...
2025-06-17 23:21:10,684 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:21:10,685 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:21:10,686 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:21:10,686 - INFO - Creating data loaders...
2025-06-17 23:21:10,687 - INFO - Checking a sample batch...
2025-06-17 23:21:11,734 - WARNING - Error checking sample batch: Caught ImportError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 153, in decode_example
    import librosa
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/__init__.py", line 209, in <module>
    from . import core
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/__init__.py", line 5, in <module>
    from .convert import *  # pylint: disable=wildcard-import
    ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/convert.py", line 7, in <module>
    from . import notation
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/notation.py", line 8, in <module>
    from ..util.exceptions import ParameterError
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/util/__init__.py", line 78, in <module>
    from .files import *  # pylint: disable=wildcard-import
    ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/util/files.py", line 10, in <module>
    from pkg_resources import resource_filename
ModuleNotFoundError: No module named 'pkg_resources'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 156, in decode_example
    raise ImportError("To support decoding audio files, please install 'librosa' and 'soundfile'.") from err
ImportError: To support decoding audio files, please install 'librosa' and 'soundfile'.

2025-06-17 23:21:11,734 - INFO - Initializing model...
2025-06-17 23:21:13,820 - INFO - Partial freezing: unfreezing last 5 text layers and 5 audio layers
2025-06-17 23:21:13,821 - INFO - Unfreezing text encoder layer 19
2025-06-17 23:21:13,822 - INFO - Unfreezing text encoder layer 20
2025-06-17 23:21:13,822 - INFO - Unfreezing text encoder layer 21
2025-06-17 23:21:13,822 - INFO - Unfreezing text encoder layer 22
2025-06-17 23:21:13,822 - INFO - Unfreezing text encoder layer 23
2025-06-17 23:21:13,823 - INFO - Unfreezing audio encoder layer 19
2025-06-17 23:21:13,824 - INFO - Unfreezing audio encoder layer 20
2025-06-17 23:21:13,824 - INFO - Unfreezing audio encoder layer 21
2025-06-17 23:21:13,824 - INFO - Unfreezing audio encoder layer 22
2025-06-17 23:21:13,824 - INFO - Unfreezing audio encoder layer 23
2025-06-17 23:21:14,098 - INFO - Model initialized with 259,145,858 trainable parameters out of 957,899,586 total
2025-06-17 23:21:15,727 - INFO - Using discriminative learning rates: encoder_lr=3e-06, main_lr=3e-05
2025-06-17 23:21:15,727 - INFO - Encoder parameters: 252, Non-encoder parameters: 44
2025-06-17 23:21:15,727 - INFO - Scheduler setup:
2025-06-17 23:21:15,728 - INFO -   Batches per epoch: 2746
2025-06-17 23:21:15,728 - INFO -   Accumulation steps: 16
2025-06-17 23:21:15,728 - INFO -   Optimizer steps per epoch: 172
2025-06-17 23:21:15,728 - INFO -   Total optimizer steps: 5160
2025-06-17 23:21:15,728 - INFO -   Warmup steps: 500
2025-06-17 23:21:15,728 - INFO - Validating gradient accumulation setup...
2025-06-17 23:21:15,728 - INFO - Validating gradient accumulation with 16 steps...
2025-06-17 23:21:16,193 - WARNING - Gradient accumulation validation failed: Caught ImportError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 153, in decode_example
    import librosa
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/__init__.py", line 209, in <module>
    from . import core
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/__init__.py", line 5, in <module>
    from .convert import *  # pylint: disable=wildcard-import
    ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/convert.py", line 7, in <module>
    from . import notation
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/notation.py", line 8, in <module>
    from ..util.exceptions import ParameterError
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/util/__init__.py", line 78, in <module>
    from .files import *  # pylint: disable=wildcard-import
    ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/util/files.py", line 10, in <module>
    from pkg_resources import resource_filename
ModuleNotFoundError: No module named 'pkg_resources'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 156, in decode_example
    raise ImportError("To support decoding audio files, please install 'librosa' and 'soundfile'.") from err
ImportError: To support decoding audio files, please install 'librosa' and 'soundfile'.

2025-06-17 23:21:16,195 - WARNING - Continuing with training anyway...
2025-06-17 23:21:16,195 - INFO - Starting training for 30 epochs
2025-06-17 23:21:17,091 - ERROR - Error in epoch 1: Caught ImportError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 153, in decode_example
    import librosa
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/__init__.py", line 209, in <module>
    from . import core
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/__init__.py", line 5, in <module>
    from .convert import *  # pylint: disable=wildcard-import
    ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/convert.py", line 7, in <module>
    from . import notation
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/notation.py", line 8, in <module>
    from ..util.exceptions import ParameterError
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/util/__init__.py", line 78, in <module>
    from .files import *  # pylint: disable=wildcard-import
    ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/util/files.py", line 10, in <module>
    from pkg_resources import resource_filename
ModuleNotFoundError: No module named 'pkg_resources'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 156, in decode_example
    raise ImportError("To support decoding audio files, please install 'librosa' and 'soundfile'.") from err
ImportError: To support decoding audio files, please install 'librosa' and 'soundfile'.

2025-06-17 23:21:18,097 - ERROR - Error in epoch 2: Caught ImportError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 153, in decode_example
    import librosa
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/__init__.py", line 209, in <module>
    from . import core
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/__init__.py", line 5, in <module>
    from .convert import *  # pylint: disable=wildcard-import
    ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/convert.py", line 7, in <module>
    from . import notation
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/notation.py", line 8, in <module>
    from ..util.exceptions import ParameterError
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/util/__init__.py", line 78, in <module>
    from .files import *  # pylint: disable=wildcard-import
    ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/util/files.py", line 10, in <module>
    from pkg_resources import resource_filename
ModuleNotFoundError: No module named 'pkg_resources'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 156, in decode_example
    raise ImportError("To support decoding audio files, please install 'librosa' and 'soundfile'.") from err
ImportError: To support decoding audio files, please install 'librosa' and 'soundfile'.

2025-06-17 23:25:38,923 - INFO - Training with parameters:
2025-06-17 23:25:38,923 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:25:38,923 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:25:38,923 - INFO -   Freeze encoders: partial
2025-06-17 23:25:38,923 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:25:38,923 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:25:38,923 - INFO -   Use cross-modal attention: True
2025-06-17 23:25:38,923 - INFO -   Use attentive pooling: True
2025-06-17 23:25:38,923 - INFO -   Use word-level alignment: False
2025-06-17 23:25:38,923 - INFO -   Batch size: 8
2025-06-17 23:25:38,924 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:25:38,924 - INFO -   Effective batch size: 128
2025-06-17 23:25:38,924 - INFO -   Mixed precision training: False
2025-06-17 23:25:38,924 - INFO -   Learning rate: 3e-05
2025-06-17 23:25:38,924 - INFO -   Temperature: 0.1
2025-06-17 23:25:38,924 - INFO -   Projection dimension: 1024
2025-06-17 23:25:38,924 - INFO -   Training samples: 21968
2025-06-17 23:25:38,924 - INFO -   Validation samples: 9464
2025-06-17 23:25:38,924 - INFO -   Test samples: 9467
2025-06-17 23:25:38,924 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:25:38,924 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:25:39,530 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:25:39,531 - INFO - Creating datasets...
2025-06-17 23:25:39,533 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:25:39,535 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:25:39,537 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:25:39,537 - INFO - Creating data loaders...
2025-06-17 23:25:39,538 - INFO - Checking a sample batch...
2025-06-17 23:25:40,196 - WARNING - Error checking sample batch: Caught ImportError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 153, in decode_example
    import librosa
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/__init__.py", line 209, in <module>
    from . import core
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/__init__.py", line 5, in <module>
    from .convert import *  # pylint: disable=wildcard-import
    ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/convert.py", line 7, in <module>
    from . import notation
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/notation.py", line 8, in <module>
    from ..util.exceptions import ParameterError
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/util/__init__.py", line 78, in <module>
    from .files import *  # pylint: disable=wildcard-import
    ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/util/files.py", line 10, in <module>
    from pkg_resources import resource_filename
ModuleNotFoundError: No module named 'pkg_resources'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 156, in decode_example
    raise ImportError("To support decoding audio files, please install 'librosa' and 'soundfile'.") from err
ImportError: To support decoding audio files, please install 'librosa' and 'soundfile'.

2025-06-17 23:25:40,197 - INFO - Initializing model...
2025-06-17 23:27:26,577 - INFO - Training with parameters:
2025-06-17 23:27:26,577 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:27:26,578 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:27:26,578 - INFO -   Freeze encoders: partial
2025-06-17 23:27:26,578 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:27:26,578 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:27:26,578 - INFO -   Use cross-modal attention: True
2025-06-17 23:27:26,578 - INFO -   Use attentive pooling: True
2025-06-17 23:27:26,578 - INFO -   Use word-level alignment: False
2025-06-17 23:27:26,578 - INFO -   Batch size: 8
2025-06-17 23:27:26,578 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:27:26,578 - INFO -   Effective batch size: 128
2025-06-17 23:27:26,578 - INFO -   Mixed precision training: False
2025-06-17 23:27:26,578 - INFO -   Learning rate: 3e-05
2025-06-17 23:27:26,579 - INFO -   Temperature: 0.1
2025-06-17 23:27:26,579 - INFO -   Projection dimension: 1024
2025-06-17 23:27:26,579 - INFO -   Training samples: 21968
2025-06-17 23:27:26,579 - INFO -   Validation samples: 9464
2025-06-17 23:27:26,579 - INFO -   Test samples: 9467
2025-06-17 23:27:26,579 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:27:26,579 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:27:27,208 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:27:27,208 - INFO - Creating datasets...
2025-06-17 23:27:27,210 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:27:27,211 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:27:27,213 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:27:27,213 - INFO - Creating data loaders...
2025-06-17 23:27:27,215 - INFO - Checking a sample batch...
2025-06-17 23:27:27,909 - WARNING - Error checking sample batch: Caught ModuleNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/training/trainer_unfreeze.py", line 871, in __getitem__
    item = self.dataset[idx]
           ~~~~~~~~~~~~^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2777, in __getitem__
    return self._getitem(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/arrow_dataset.py", line 2762, in _getitem
    formatted_output = format_table(
                       ^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 653, in format_table
    return formatter(pa_table, query_type=query_type)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 406, in __call__
    return self.format_row(pa_table)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 455, in format_row
    row = self.python_features_decoder.decode_row(row)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/formatting/formatting.py", line 223, in decode_row
    return self.features.decode_example(row, token_per_repo_id=self.token_per_repo_id) if self.features else row
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2100, in decode_example
    return {
           ^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 2101, in <dictcomp>
    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/features.py", line 1414, in decode_nested_example
    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id) if obj is not None else None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/datasets/features/audio.py", line 188, in decode_example
    array = librosa.to_mono(array)
            ^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/lazy_loader/__init__.py", line 83, in __getattr__
    attr = getattr(submod, name)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/lazy_loader/__init__.py", line 82, in __getattr__
    submod = importlib.import_module(submod_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/audio.py", line 19, in <module>
    from .convert import frames_to_samples, time_to_samples
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/convert.py", line 7, in <module>
    from . import notation
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/notation.py", line 8, in <module>
    from .intervals import INTERVALS
  File "/home/yperezhohin/speech_transcript_embeddings/.venv/lib/python3.11/site-packages/librosa/core/intervals.py", line 8, in <module>
    from pkg_resources import resource_filename
ModuleNotFoundError: No module named 'pkg_resources'

2025-06-17 23:27:27,910 - INFO - Initializing model...
2025-06-17 23:27:38,892 - INFO - Partial freezing: unfreezing last 5 text layers and 5 audio layers
2025-06-17 23:27:38,894 - INFO - Unfreezing text encoder layer 19
2025-06-17 23:27:38,894 - INFO - Unfreezing text encoder layer 20
2025-06-17 23:27:38,894 - INFO - Unfreezing text encoder layer 21
2025-06-17 23:27:38,894 - INFO - Unfreezing text encoder layer 22
2025-06-17 23:27:38,894 - INFO - Unfreezing text encoder layer 23
2025-06-17 23:27:38,897 - INFO - Unfreezing audio encoder layer 19
2025-06-17 23:27:38,897 - INFO - Unfreezing audio encoder layer 20
2025-06-17 23:27:38,897 - INFO - Unfreezing audio encoder layer 21
2025-06-17 23:27:38,897 - INFO - Unfreezing audio encoder layer 22
2025-06-17 23:27:38,898 - INFO - Unfreezing audio encoder layer 23
2025-06-17 23:27:39,237 - INFO - Model initialized with 259,145,858 trainable parameters out of 957,899,586 total
2025-06-17 23:30:35,230 - INFO - Training with parameters:
2025-06-17 23:30:35,230 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:30:35,230 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:30:35,230 - INFO -   Freeze encoders: partial
2025-06-17 23:30:35,230 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:30:35,230 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:30:35,230 - INFO -   Use cross-modal attention: True
2025-06-17 23:30:35,230 - INFO -   Use attentive pooling: True
2025-06-17 23:30:35,230 - INFO -   Use word-level alignment: False
2025-06-17 23:30:35,231 - INFO -   Batch size: 8
2025-06-17 23:30:35,231 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:30:35,231 - INFO -   Effective batch size: 128
2025-06-17 23:30:35,231 - INFO -   Mixed precision training: False
2025-06-17 23:30:35,231 - INFO -   Learning rate: 3e-05
2025-06-17 23:30:35,231 - INFO -   Temperature: 0.1
2025-06-17 23:30:35,231 - INFO -   Projection dimension: 1024
2025-06-17 23:30:35,231 - INFO -   Training samples: 21968
2025-06-17 23:30:35,231 - INFO -   Validation samples: 9464
2025-06-17 23:30:35,231 - INFO -   Test samples: 9467
2025-06-17 23:30:35,231 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:30:35,232 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:30:35,927 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:30:35,927 - INFO - Creating datasets...
2025-06-17 23:30:35,929 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:30:35,930 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:30:35,932 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:30:35,932 - INFO - Creating data loaders...
2025-06-17 23:30:35,935 - INFO - Checking a sample batch...
2025-06-17 23:32:34,463 - INFO - Training with parameters:
2025-06-17 23:32:34,463 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:32:34,463 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:32:34,463 - INFO -   Freeze encoders: partial
2025-06-17 23:32:34,463 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:32:34,463 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:32:34,463 - INFO -   Use cross-modal attention: True
2025-06-17 23:32:34,463 - INFO -   Use attentive pooling: True
2025-06-17 23:32:34,463 - INFO -   Use word-level alignment: False
2025-06-17 23:32:34,463 - INFO -   Batch size: 8
2025-06-17 23:32:34,463 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:32:34,463 - INFO -   Effective batch size: 128
2025-06-17 23:32:34,463 - INFO -   Mixed precision training: False
2025-06-17 23:32:34,464 - INFO -   Learning rate: 3e-05
2025-06-17 23:32:34,464 - INFO -   Temperature: 0.1
2025-06-17 23:32:34,464 - INFO -   Projection dimension: 1024
2025-06-17 23:32:34,464 - INFO -   Training samples: 21968
2025-06-17 23:32:34,464 - INFO -   Validation samples: 9464
2025-06-17 23:32:34,464 - INFO -   Test samples: 9467
2025-06-17 23:32:34,464 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:32:34,464 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:32:34,975 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:32:34,976 - INFO - Creating datasets...
2025-06-17 23:32:34,977 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:32:34,978 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:32:34,980 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:32:34,980 - INFO - Creating data loaders...
2025-06-17 23:32:34,982 - INFO - Checking a sample batch...
2025-06-17 23:32:59,159 - INFO -   input_ids_pos: torch.Size([8, 256])
2025-06-17 23:32:59,159 - INFO -   attention_mask_pos: torch.Size([8, 256])
2025-06-17 23:32:59,160 - INFO -   input_ids_neg: torch.Size([8, 256])
2025-06-17 23:32:59,160 - INFO -   attention_mask_neg: torch.Size([8, 256])
2025-06-17 23:32:59,160 - INFO -   input_values: torch.Size([8, 328, 160])
2025-06-17 23:32:59,160 - INFO -   attention_mask_audio: torch.Size([8, 328])
2025-06-17 23:32:59,160 - INFO -   is_corrupted: torch.Size([8])
2025-06-17 23:32:59,161 - INFO - Initializing model...
2025-06-17 23:33:00,952 - INFO - Partial freezing: unfreezing last 5 text layers and 5 audio layers
2025-06-17 23:33:00,953 - INFO - Unfreezing text encoder layer 19
2025-06-17 23:33:00,954 - INFO - Unfreezing text encoder layer 20
2025-06-17 23:33:00,954 - INFO - Unfreezing text encoder layer 21
2025-06-17 23:33:00,954 - INFO - Unfreezing text encoder layer 22
2025-06-17 23:33:00,954 - INFO - Unfreezing text encoder layer 23
2025-06-17 23:33:00,956 - INFO - Unfreezing audio encoder layer 19
2025-06-17 23:33:00,956 - INFO - Unfreezing audio encoder layer 20
2025-06-17 23:33:00,956 - INFO - Unfreezing audio encoder layer 21
2025-06-17 23:33:00,956 - INFO - Unfreezing audio encoder layer 22
2025-06-17 23:33:00,956 - INFO - Unfreezing audio encoder layer 23
2025-06-17 23:33:01,355 - INFO - Model initialized with 259,145,858 trainable parameters out of 957,899,586 total
2025-06-17 23:33:02,565 - INFO - Using discriminative learning rates: encoder_lr=3e-06, main_lr=3e-05
2025-06-17 23:33:02,565 - INFO - Encoder parameters: 252, Non-encoder parameters: 44
2025-06-17 23:33:02,565 - INFO - Scheduler setup:
2025-06-17 23:33:02,565 - INFO -   Batches per epoch: 2746
2025-06-17 23:33:02,565 - INFO -   Accumulation steps: 16
2025-06-17 23:33:02,565 - INFO -   Optimizer steps per epoch: 172
2025-06-17 23:33:02,565 - INFO -   Total optimizer steps: 5160
2025-06-17 23:33:02,565 - INFO -   Warmup steps: 500
2025-06-17 23:33:02,566 - INFO - Validating gradient accumulation setup...
2025-06-17 23:33:02,566 - INFO - Validating gradient accumulation with 16 steps...
2025-06-17 23:33:10,002 - WARNING - Not enough test batches (10) for accumulation_steps (16)
2025-06-17 23:33:10,003 - INFO - Starting training for 30 epochs
2025-06-17 23:33:56,990 - INFO - Training with parameters:
2025-06-17 23:33:56,990 - INFO -   Text model: sentence-transformers/all-roberta-large-v1
2025-06-17 23:33:56,990 - INFO -   Audio model: facebook/w2v-bert-2.0
2025-06-17 23:33:56,990 - INFO -   Freeze encoders: partial
2025-06-17 23:33:56,990 - INFO -   Text layers to unfreeze: 5
2025-06-17 23:33:56,990 - INFO -   Audio layers to unfreeze: 5
2025-06-17 23:33:56,991 - INFO -   Use cross-modal attention: True
2025-06-17 23:33:56,991 - INFO -   Use attentive pooling: True
2025-06-17 23:33:56,991 - INFO -   Use word-level alignment: False
2025-06-17 23:33:56,991 - INFO -   Batch size: 8
2025-06-17 23:33:56,991 - INFO -   Gradient accumulation steps: 16
2025-06-17 23:33:56,991 - INFO -   Effective batch size: 128
2025-06-17 23:33:56,991 - INFO -   Mixed precision training: False
2025-06-17 23:33:56,991 - INFO -   Learning rate: 3e-05
2025-06-17 23:33:56,991 - INFO -   Temperature: 0.1
2025-06-17 23:33:56,991 - INFO -   Projection dimension: 1024
2025-06-17 23:33:56,991 - INFO -   Training samples: 21968
2025-06-17 23:33:56,992 - INFO -   Validation samples: 9464
2025-06-17 23:33:56,992 - INFO -   Test samples: 9467
2025-06-17 23:33:56,992 - INFO -   Max audio length: 480000 samples (30.00 seconds at 16kHz)
2025-06-17 23:33:56,992 - INFO - Loading tokenizer and feature extractor...
2025-06-17 23:33:57,503 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:33:57,504 - INFO - Creating datasets...
2025-06-17 23:33:57,505 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:33:57,507 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:33:57,516 - INFO - Feature extractor output keys: ['input_features', 'attention_mask']
2025-06-17 23:33:57,516 - INFO - Creating data loaders...
2025-06-17 23:33:57,517 - INFO - Checking a sample batch...
2025-06-17 23:34:04,391 - INFO -   input_ids_pos: torch.Size([8, 256])
2025-06-17 23:34:04,392 - INFO -   attention_mask_pos: torch.Size([8, 256])
2025-06-17 23:34:04,392 - INFO -   input_ids_neg: torch.Size([8, 256])
2025-06-17 23:34:04,392 - INFO -   attention_mask_neg: torch.Size([8, 256])
2025-06-17 23:34:04,393 - INFO -   input_values: torch.Size([8, 328, 160])
2025-06-17 23:34:04,393 - INFO -   attention_mask_audio: torch.Size([8, 328])
2025-06-17 23:34:04,393 - INFO -   is_corrupted: torch.Size([8])
2025-06-17 23:34:04,393 - INFO - Initializing model...
2025-06-17 23:34:06,198 - INFO - Partial freezing: unfreezing last 5 text layers and 5 audio layers
2025-06-17 23:34:06,199 - INFO - Unfreezing text encoder layer 19
2025-06-17 23:34:06,199 - INFO - Unfreezing text encoder layer 20
2025-06-17 23:34:06,199 - INFO - Unfreezing text encoder layer 21
2025-06-17 23:34:06,200 - INFO - Unfreezing text encoder layer 22
2025-06-17 23:34:06,200 - INFO - Unfreezing text encoder layer 23
2025-06-17 23:34:06,201 - INFO - Unfreezing audio encoder layer 19
2025-06-17 23:34:06,201 - INFO - Unfreezing audio encoder layer 20
2025-06-17 23:34:06,202 - INFO - Unfreezing audio encoder layer 21
2025-06-17 23:34:06,202 - INFO - Unfreezing audio encoder layer 22
2025-06-17 23:34:06,202 - INFO - Unfreezing audio encoder layer 23
2025-06-17 23:34:06,472 - INFO - Model initialized with 259,145,858 trainable parameters out of 957,899,586 total
2025-06-17 23:34:07,913 - INFO - Using discriminative learning rates: encoder_lr=3e-06, main_lr=3e-05
2025-06-17 23:34:07,913 - INFO - Encoder parameters: 252, Non-encoder parameters: 44
2025-06-17 23:34:07,913 - INFO - Scheduler setup:
2025-06-17 23:34:07,913 - INFO -   Batches per epoch: 2746
2025-06-17 23:34:07,913 - INFO -   Accumulation steps: 16
2025-06-17 23:34:07,913 - INFO -   Optimizer steps per epoch: 172
2025-06-17 23:34:07,914 - INFO -   Total optimizer steps: 5160
2025-06-17 23:34:07,914 - INFO -   Warmup steps: 500
2025-06-17 23:34:07,914 - INFO - Validating gradient accumulation setup...
2025-06-17 23:34:07,914 - INFO - Validating gradient accumulation with 16 steps...
2025-06-17 23:34:15,540 - WARNING - Not enough test batches (10) for accumulation_steps (16)
2025-06-17 23:34:15,541 - INFO - Starting training for 30 epochs
2025-06-18 01:15:05,636 - INFO - Epoch 1: Total optimizer steps: 172
2025-06-18 01:32:41,553 - INFO - Validation metrics:
2025-06-18 01:32:41,554 - INFO -   Loss: 0.3914
2025-06-18 01:32:41,554 - INFO -   Average similarity: -0.0744
2025-06-18 01:32:41,554 - INFO -   Median similarity: -0.0501
2025-06-18 01:32:41,554 - INFO -   Clean sample similarity: -0.0744
2025-06-18 01:32:41,555 - INFO -   Corrupted sample similarity: -0.2117
2025-06-18 01:32:41,555 - INFO -   Similarity gap (clean - corrupt): 0.1373
2025-06-18 01:32:41,662 - INFO - Epoch 1/30 - Train Loss: 0.5920, Val Loss: 0.3914, Clean Sim: -0.0744, Corrupt Sim: -0.2117, Gap: 0.1373, Time: 7106.12s
2025-06-18 01:32:41,662 - INFO - New best validation loss: 0.3914
2025-06-18 01:32:51,185 - INFO - New best similarity gap: 0.1373
2025-06-18 03:14:35,025 - INFO - Epoch 2: Total optimizer steps: 172
2025-06-18 03:33:15,726 - INFO - Validation metrics:
2025-06-18 03:33:15,727 - INFO -   Loss: 0.3116
2025-06-18 03:33:15,727 - INFO -   Average similarity: -0.0019
2025-06-18 03:33:15,727 - INFO -   Median similarity: 0.0339
2025-06-18 03:33:15,727 - INFO -   Clean sample similarity: -0.0019
2025-06-18 03:33:15,727 - INFO -   Corrupted sample similarity: -0.2163
2025-06-18 03:33:15,727 - INFO -   Similarity gap (clean - corrupt): 0.2144
2025-06-18 03:33:15,854 - INFO - Epoch 2/30 - Train Loss: 0.4141, Val Loss: 0.3116, Clean Sim: -0.0019, Corrupt Sim: -0.2163, Gap: 0.2144, Time: 7206.81s
2025-06-18 03:33:15,854 - INFO - New best validation loss: 0.3116
2025-06-18 03:33:28,982 - INFO - New best similarity gap: 0.2144
2025-06-18 05:13:41,910 - INFO - Epoch 3: Total optimizer steps: 172
2025-06-18 05:31:06,119 - INFO - Validation metrics:
2025-06-18 05:31:06,119 - INFO -   Loss: 0.2788
2025-06-18 05:31:06,120 - INFO -   Average similarity: 0.1997
2025-06-18 05:31:06,120 - INFO -   Median similarity: 0.2113
2025-06-18 05:31:06,120 - INFO -   Clean sample similarity: 0.1997
2025-06-18 05:31:06,120 - INFO -   Corrupted sample similarity: -0.0712
2025-06-18 05:31:06,120 - INFO -   Similarity gap (clean - corrupt): 0.2709
2025-06-18 05:31:06,256 - INFO - Epoch 3/30 - Train Loss: 0.3391, Val Loss: 0.2788, Clean Sim: 0.1997, Corrupt Sim: -0.0712, Gap: 0.2709, Time: 7033.86s
2025-06-18 05:31:06,257 - INFO - New best validation loss: 0.2788
2025-06-18 05:31:18,888 - INFO - New best similarity gap: 0.2709
2025-06-18 07:13:39,476 - INFO - Epoch 4: Total optimizer steps: 172
2025-06-18 07:32:10,541 - INFO - Validation metrics:
2025-06-18 07:32:10,541 - INFO -   Loss: 0.2653
2025-06-18 07:32:10,541 - INFO -   Average similarity: 0.2897
2025-06-18 07:32:10,541 - INFO -   Median similarity: 0.3004
2025-06-18 07:32:10,541 - INFO -   Clean sample similarity: 0.2897
2025-06-18 07:32:10,541 - INFO -   Corrupted sample similarity: -0.0160
2025-06-18 07:32:10,541 - INFO -   Similarity gap (clean - corrupt): 0.3057
2025-06-18 07:32:10,717 - INFO - Epoch 4/30 - Train Loss: 0.2562, Val Loss: 0.2653, Clean Sim: 0.2897, Corrupt Sim: -0.0160, Gap: 0.3057, Time: 7228.95s
2025-06-18 07:32:10,718 - INFO - New best validation loss: 0.2653
2025-06-18 07:32:23,272 - INFO - New best similarity gap: 0.3057
2025-06-18 09:12:42,420 - INFO - Epoch 5: Total optimizer steps: 172
2025-06-18 09:30:53,540 - INFO - Validation metrics:
2025-06-18 09:30:53,541 - INFO -   Loss: 0.2422
2025-06-18 09:30:53,541 - INFO -   Average similarity: 0.3392
2025-06-18 09:30:53,541 - INFO -   Median similarity: 0.3508
2025-06-18 09:30:53,541 - INFO -   Clean sample similarity: 0.3392
2025-06-18 09:30:53,541 - INFO -   Corrupted sample similarity: -0.0246
2025-06-18 09:30:53,541 - INFO -   Similarity gap (clean - corrupt): 0.3638
2025-06-18 09:30:53,699 - INFO - Epoch 5/30 - Train Loss: 0.1826, Val Loss: 0.2422, Clean Sim: 0.3392, Corrupt Sim: -0.0246, Gap: 0.3638, Time: 7086.80s
2025-06-18 09:30:53,700 - INFO - New best validation loss: 0.2422
2025-06-18 09:31:07,031 - INFO - New best similarity gap: 0.3638
2025-06-18 11:29:28,549 - INFO - Epoch 6: Total optimizer steps: 172
2025-06-18 11:47:23,026 - INFO - Validation metrics:
2025-06-18 11:47:23,027 - INFO -   Loss: 0.2975
2025-06-18 11:47:23,027 - INFO -   Average similarity: 0.4046
2025-06-18 11:47:23,027 - INFO -   Median similarity: 0.4117
2025-06-18 11:47:23,027 - INFO -   Clean sample similarity: 0.4046
2025-06-18 11:47:23,027 - INFO -   Corrupted sample similarity: 0.0880
2025-06-18 11:47:23,027 - INFO -   Similarity gap (clean - corrupt): 0.3166
2025-06-18 11:47:23,168 - INFO - Epoch 6/30 - Train Loss: 0.1155, Val Loss: 0.2975, Clean Sim: 0.4046, Corrupt Sim: 0.0880, Gap: 0.3166, Time: 7137.06s
2025-06-18 13:28:19,885 - INFO - Epoch 7: Total optimizer steps: 172
2025-06-18 13:45:48,613 - INFO - Validation metrics:
2025-06-18 13:45:48,613 - INFO -   Loss: 0.2885
2025-06-18 13:45:48,613 - INFO -   Average similarity: 0.4093
2025-06-18 13:45:48,613 - INFO -   Median similarity: 0.4190
2025-06-18 13:45:48,613 - INFO -   Clean sample similarity: 0.4093
2025-06-18 13:45:48,613 - INFO -   Corrupted sample similarity: 0.0890
2025-06-18 13:45:48,613 - INFO -   Similarity gap (clean - corrupt): 0.3203
2025-06-18 13:45:48,772 - INFO - Epoch 7/30 - Train Loss: 0.0789, Val Loss: 0.2885, Clean Sim: 0.4093, Corrupt Sim: 0.0890, Gap: 0.3203, Time: 7095.81s
2025-06-18 15:26:08,066 - INFO - Epoch 8: Total optimizer steps: 172
2025-06-18 15:44:16,445 - INFO - Validation metrics:
2025-06-18 15:44:16,446 - INFO -   Loss: 0.2794
2025-06-18 15:44:16,446 - INFO -   Average similarity: 0.3985
2025-06-18 15:44:16,446 - INFO -   Median similarity: 0.4046
2025-06-18 15:44:16,446 - INFO -   Clean sample similarity: 0.3985
2025-06-18 15:44:16,446 - INFO -   Corrupted sample similarity: 0.0614
2025-06-18 15:44:16,446 - INFO -   Similarity gap (clean - corrupt): 0.3371
2025-06-18 15:44:16,592 - INFO - Epoch 8/30 - Train Loss: 0.0656, Val Loss: 0.2794, Clean Sim: 0.3985, Corrupt Sim: 0.0614, Gap: 0.3371, Time: 7098.05s
2025-06-18 17:25:16,789 - INFO - Epoch 9: Total optimizer steps: 172
2025-06-18 17:42:58,926 - INFO - Validation metrics:
2025-06-18 17:42:58,927 - INFO -   Loss: 0.2854
2025-06-18 17:42:58,927 - INFO -   Average similarity: 0.3883
2025-06-18 17:42:58,927 - INFO -   Median similarity: 0.3942
2025-06-18 17:42:58,927 - INFO -   Clean sample similarity: 0.3883
2025-06-18 17:42:58,927 - INFO -   Corrupted sample similarity: 0.0711
2025-06-18 17:42:58,928 - INFO -   Similarity gap (clean - corrupt): 0.3172
2025-06-18 17:42:59,092 - INFO - Epoch 9/30 - Train Loss: 0.0554, Val Loss: 0.2854, Clean Sim: 0.3883, Corrupt Sim: 0.0711, Gap: 0.3172, Time: 7112.99s
2025-06-18 19:23:27,724 - INFO - Epoch 10: Total optimizer steps: 172
2025-06-18 19:40:33,766 - INFO - Validation metrics:
2025-06-18 19:40:33,766 - INFO -   Loss: 0.2783
2025-06-18 19:40:33,766 - INFO -   Average similarity: 0.4353
2025-06-18 19:40:33,766 - INFO -   Median similarity: 0.4442
2025-06-18 19:40:33,766 - INFO -   Clean sample similarity: 0.4353
2025-06-18 19:40:33,767 - INFO -   Corrupted sample similarity: 0.0963
2025-06-18 19:40:33,767 - INFO -   Similarity gap (clean - corrupt): 0.3391
2025-06-18 19:40:33,914 - INFO - Epoch 10/30 - Train Loss: 0.0471, Val Loss: 0.2783, Clean Sim: 0.4353, Corrupt Sim: 0.0963, Gap: 0.3391, Time: 7044.92s
2025-06-18 21:37:45,573 - INFO - Epoch 11: Total optimizer steps: 172
2025-06-18 21:55:24,371 - INFO - Validation metrics:
2025-06-18 21:55:24,373 - INFO -   Loss: 0.2938
2025-06-18 21:55:24,373 - INFO -   Average similarity: 0.4414
2025-06-18 21:55:24,373 - INFO -   Median similarity: 0.4461
2025-06-18 21:55:24,373 - INFO -   Clean sample similarity: 0.4414
2025-06-18 21:55:24,373 - INFO -   Corrupted sample similarity: 0.0980
2025-06-18 21:55:24,373 - INFO -   Similarity gap (clean - corrupt): 0.3434
2025-06-18 21:55:24,537 - INFO - Epoch 11/30 - Train Loss: 0.0400, Val Loss: 0.2938, Clean Sim: 0.4414, Corrupt Sim: 0.0980, Gap: 0.3434, Time: 7085.08s
2025-06-18 23:37:42,541 - INFO - Epoch 12: Total optimizer steps: 172
2025-06-18 23:55:11,921 - INFO - Validation metrics:
2025-06-18 23:55:11,921 - INFO -   Loss: 0.3031
2025-06-18 23:55:11,921 - INFO -   Average similarity: 0.4522
2025-06-18 23:55:11,921 - INFO -   Median similarity: 0.4604
2025-06-18 23:55:11,922 - INFO -   Clean sample similarity: 0.4522
2025-06-18 23:55:11,922 - INFO -   Corrupted sample similarity: 0.1256
2025-06-18 23:55:11,922 - INFO -   Similarity gap (clean - corrupt): 0.3266
2025-06-18 23:55:12,084 - INFO - Epoch 12/30 - Train Loss: 0.0343, Val Loss: 0.3031, Clean Sim: 0.4522, Corrupt Sim: 0.1256, Gap: 0.3266, Time: 7176.74s
2025-06-19 01:37:49,121 - INFO - Epoch 13: Total optimizer steps: 172
2025-06-19 01:55:57,199 - INFO - Validation metrics:
2025-06-19 01:55:57,200 - INFO -   Loss: 0.3152
2025-06-19 01:55:57,200 - INFO -   Average similarity: 0.4604
2025-06-19 01:55:57,200 - INFO -   Median similarity: 0.4678
2025-06-19 01:55:57,200 - INFO -   Clean sample similarity: 0.4604
2025-06-19 01:55:57,200 - INFO -   Corrupted sample similarity: 0.1561
2025-06-19 01:55:57,201 - INFO -   Similarity gap (clean - corrupt): 0.3043
2025-06-19 01:55:57,369 - INFO - Epoch 13/30 - Train Loss: 0.0307, Val Loss: 0.3152, Clean Sim: 0.4604, Corrupt Sim: 0.1561, Gap: 0.3043, Time: 7235.58s
2025-06-19 03:36:37,204 - INFO - Epoch 14: Total optimizer steps: 172
2025-06-19 03:54:03,048 - INFO - Validation metrics:
2025-06-19 03:54:03,049 - INFO -   Loss: 0.3152
2025-06-19 03:54:03,049 - INFO -   Average similarity: 0.4905
2025-06-19 03:54:03,049 - INFO -   Median similarity: 0.4977
2025-06-19 03:54:03,049 - INFO -   Clean sample similarity: 0.4905
2025-06-19 03:54:03,049 - INFO -   Corrupted sample similarity: 0.1624
2025-06-19 03:54:03,049 - INFO -   Similarity gap (clean - corrupt): 0.3281
2025-06-19 03:54:03,195 - INFO - Epoch 14/30 - Train Loss: 0.0277, Val Loss: 0.3152, Clean Sim: 0.4905, Corrupt Sim: 0.1624, Gap: 0.3281, Time: 7075.73s
2025-06-19 05:36:32,544 - INFO - Epoch 15: Total optimizer steps: 172
2025-06-19 05:54:34,009 - INFO - Validation metrics:
2025-06-19 05:54:34,009 - INFO -   Loss: 0.3202
2025-06-19 05:54:34,009 - INFO -   Average similarity: 0.4367
2025-06-19 05:54:34,009 - INFO -   Median similarity: 0.4419
2025-06-19 05:54:34,009 - INFO -   Clean sample similarity: 0.4367
2025-06-19 05:54:34,009 - INFO -   Corrupted sample similarity: 0.1495
2025-06-19 05:54:34,009 - INFO -   Similarity gap (clean - corrupt): 0.2872
2025-06-19 05:54:34,154 - INFO - Epoch 15/30 - Train Loss: 0.0247, Val Loss: 0.3202, Clean Sim: 0.4367, Corrupt Sim: 0.1495, Gap: 0.2872, Time: 7222.11s
2025-06-19 07:51:02,335 - INFO - Epoch 16: Total optimizer steps: 172
2025-06-19 08:09:37,856 - INFO - Validation metrics:
2025-06-19 08:09:37,857 - INFO -   Loss: 0.3376
2025-06-19 08:09:37,857 - INFO -   Average similarity: 0.4572
2025-06-19 08:09:37,857 - INFO -   Median similarity: 0.4637
2025-06-19 08:09:37,857 - INFO -   Clean sample similarity: 0.4572
2025-06-19 08:09:37,857 - INFO -   Corrupted sample similarity: 0.1838
2025-06-19 08:09:37,857 - INFO -   Similarity gap (clean - corrupt): 0.2734
2025-06-19 08:09:37,995 - INFO - Epoch 16/30 - Train Loss: 0.0223, Val Loss: 0.3376, Clean Sim: 0.4572, Corrupt Sim: 0.1838, Gap: 0.2734, Time: 7057.75s
2025-06-19 09:51:26,124 - INFO - Epoch 17: Total optimizer steps: 172
2025-06-19 10:08:32,819 - INFO - Validation metrics:
2025-06-19 10:08:32,819 - INFO -   Loss: 0.3511
2025-06-19 10:08:32,819 - INFO -   Average similarity: 0.5117
2025-06-19 10:08:32,819 - INFO -   Median similarity: 0.5231
2025-06-19 10:08:32,819 - INFO -   Clean sample similarity: 0.5117
2025-06-19 10:08:32,819 - INFO -   Corrupted sample similarity: 0.2397
2025-06-19 10:08:32,819 - INFO -   Similarity gap (clean - corrupt): 0.2720
2025-06-19 10:08:32,979 - INFO - Epoch 17/30 - Train Loss: 0.0200, Val Loss: 0.3511, Clean Sim: 0.5117, Corrupt Sim: 0.2397, Gap: 0.2720, Time: 7125.39s
2025-06-19 11:49:13,700 - INFO - Epoch 18: Total optimizer steps: 172
2025-06-19 12:06:36,036 - INFO - Validation metrics:
2025-06-19 12:06:36,037 - INFO -   Loss: 0.3593
2025-06-19 12:06:36,037 - INFO -   Average similarity: 0.4834
2025-06-19 12:06:36,037 - INFO -   Median similarity: 0.4901
2025-06-19 12:06:36,037 - INFO -   Clean sample similarity: 0.4834
2025-06-19 12:06:36,038 - INFO -   Corrupted sample similarity: 0.2317
2025-06-19 12:06:36,038 - INFO -   Similarity gap (clean - corrupt): 0.2517
2025-06-19 12:06:36,188 - INFO - Epoch 18/30 - Train Loss: 0.0177, Val Loss: 0.3593, Clean Sim: 0.4834, Corrupt Sim: 0.2317, Gap: 0.2517, Time: 7073.19s
2025-06-19 13:47:15,299 - INFO - Epoch 19: Total optimizer steps: 172
2025-06-19 14:05:12,951 - INFO - Validation metrics:
2025-06-19 14:05:12,952 - INFO -   Loss: 0.3657
2025-06-19 14:05:12,952 - INFO -   Average similarity: 0.4791
2025-06-19 14:05:12,952 - INFO -   Median similarity: 0.4854
2025-06-19 14:05:12,952 - INFO -   Clean sample similarity: 0.4791
2025-06-19 14:05:12,952 - INFO -   Corrupted sample similarity: 0.2343
2025-06-19 14:05:12,952 - INFO -   Similarity gap (clean - corrupt): 0.2448
2025-06-19 14:05:13,091 - INFO - Epoch 19/30 - Train Loss: 0.0163, Val Loss: 0.3657, Clean Sim: 0.4791, Corrupt Sim: 0.2343, Gap: 0.2448, Time: 7107.01s
2025-06-19 15:45:47,323 - INFO - Epoch 20: Total optimizer steps: 172
2025-06-19 16:04:16,773 - INFO - Validation metrics:
2025-06-19 16:04:16,774 - INFO -   Loss: 0.3747
2025-06-19 16:04:16,774 - INFO -   Average similarity: 0.5198
2025-06-19 16:04:16,774 - INFO -   Median similarity: 0.5289
2025-06-19 16:04:16,774 - INFO -   Clean sample similarity: 0.5198
2025-06-19 16:04:16,774 - INFO -   Corrupted sample similarity: 0.2740
2025-06-19 16:04:16,774 - INFO -   Similarity gap (clean - corrupt): 0.2458
2025-06-19 16:04:16,912 - INFO - Epoch 20/30 - Train Loss: 0.0147, Val Loss: 0.3747, Clean Sim: 0.5198, Corrupt Sim: 0.2740, Gap: 0.2458, Time: 7134.14s
2025-06-19 18:03:57,611 - INFO - Epoch 21: Total optimizer steps: 172
2025-06-19 18:21:45,533 - INFO - Validation metrics:
2025-06-19 18:21:45,533 - INFO -   Loss: 0.3691
2025-06-19 18:21:45,533 - INFO -   Average similarity: 0.4897
2025-06-19 18:21:45,533 - INFO -   Median similarity: 0.4974
2025-06-19 18:21:45,534 - INFO -   Clean sample similarity: 0.4897
2025-06-19 18:21:45,534 - INFO -   Corrupted sample similarity: 0.2463
2025-06-19 18:21:45,534 - INFO -   Similarity gap (clean - corrupt): 0.2434
2025-06-19 18:21:45,685 - INFO - Epoch 21/30 - Train Loss: 0.0143, Val Loss: 0.3691, Clean Sim: 0.4897, Corrupt Sim: 0.2463, Gap: 0.2434, Time: 7238.11s
2025-06-19 20:03:41,040 - INFO - Epoch 22: Total optimizer steps: 172
2025-06-19 20:21:07,766 - INFO - Validation metrics:
2025-06-19 20:21:07,767 - INFO -   Loss: 0.3617
2025-06-19 20:21:07,767 - INFO -   Average similarity: 0.4959
2025-06-19 20:21:07,767 - INFO -   Median similarity: 0.5033
2025-06-19 20:21:07,767 - INFO -   Clean sample similarity: 0.4959
2025-06-19 20:21:07,767 - INFO -   Corrupted sample similarity: 0.2448
2025-06-19 20:21:07,767 - INFO -   Similarity gap (clean - corrupt): 0.2511
2025-06-19 20:21:07,905 - INFO - Epoch 22/30 - Train Loss: 0.0134, Val Loss: 0.3617, Clean Sim: 0.4959, Corrupt Sim: 0.2448, Gap: 0.2511, Time: 7152.82s
2025-06-19 22:00:01,358 - INFO - Epoch 23: Total optimizer steps: 172
2025-06-19 22:17:26,347 - INFO - Validation metrics:
2025-06-19 22:17:26,347 - INFO -   Loss: 0.3758
2025-06-19 22:17:26,347 - INFO -   Average similarity: 0.5148
2025-06-19 22:17:26,347 - INFO -   Median similarity: 0.5206
2025-06-19 22:17:26,348 - INFO -   Clean sample similarity: 0.5148
2025-06-19 22:17:26,348 - INFO -   Corrupted sample similarity: 0.2681
2025-06-19 22:17:26,348 - INFO -   Similarity gap (clean - corrupt): 0.2467
2025-06-19 22:17:26,487 - INFO - Epoch 23/30 - Train Loss: 0.0122, Val Loss: 0.3758, Clean Sim: 0.5148, Corrupt Sim: 0.2681, Gap: 0.2467, Time: 6969.27s
2025-06-20 00:02:52,907 - INFO - Epoch 24: Total optimizer steps: 172
2025-06-20 00:21:16,413 - INFO - Validation metrics:
2025-06-20 00:21:16,414 - INFO -   Loss: 0.3842
2025-06-20 00:21:16,414 - INFO -   Average similarity: 0.4719
2025-06-20 00:21:16,414 - INFO -   Median similarity: 0.4780
2025-06-20 00:21:16,414 - INFO -   Clean sample similarity: 0.4719
2025-06-20 00:21:16,414 - INFO -   Corrupted sample similarity: 0.2471
2025-06-20 00:21:16,414 - INFO -   Similarity gap (clean - corrupt): 0.2248
2025-06-20 00:21:16,585 - INFO - Epoch 24/30 - Train Loss: 0.0113, Val Loss: 0.3842, Clean Sim: 0.4719, Corrupt Sim: 0.2471, Gap: 0.2248, Time: 7420.84s
2025-06-20 02:02:25,241 - INFO - Epoch 25: Total optimizer steps: 172
2025-06-20 02:20:26,436 - INFO - Validation metrics:
2025-06-20 02:20:26,437 - INFO -   Loss: 0.3848
2025-06-20 02:20:26,437 - INFO -   Average similarity: 0.5029
2025-06-20 02:20:26,437 - INFO -   Median similarity: 0.5076
2025-06-20 02:20:26,437 - INFO -   Clean sample similarity: 0.5029
2025-06-20 02:20:26,437 - INFO -   Corrupted sample similarity: 0.2787
2025-06-20 02:20:26,437 - INFO -   Similarity gap (clean - corrupt): 0.2242
2025-06-20 02:20:26,603 - INFO - Epoch 25/30 - Train Loss: 0.0107, Val Loss: 0.3848, Clean Sim: 0.5029, Corrupt Sim: 0.2787, Gap: 0.2242, Time: 7139.32s
2025-06-20 04:18:09,027 - INFO - Epoch 26: Total optimizer steps: 172
2025-06-20 04:36:41,488 - INFO - Validation metrics:
2025-06-20 04:36:41,489 - INFO -   Loss: 0.3814
2025-06-20 04:36:41,489 - INFO -   Average similarity: 0.5089
2025-06-20 04:36:41,489 - INFO -   Median similarity: 0.5157
2025-06-20 04:36:41,490 - INFO -   Clean sample similarity: 0.5089
2025-06-20 04:36:41,490 - INFO -   Corrupted sample similarity: 0.2784
2025-06-20 04:36:41,490 - INFO -   Similarity gap (clean - corrupt): 0.2305
2025-06-20 04:36:41,648 - INFO - Epoch 26/30 - Train Loss: 0.0100, Val Loss: 0.3814, Clean Sim: 0.5089, Corrupt Sim: 0.2784, Gap: 0.2305, Time: 7108.61s
2025-06-20 06:18:58,397 - INFO - Epoch 27: Total optimizer steps: 172
2025-06-20 06:35:55,496 - INFO - Validation metrics:
2025-06-20 06:35:55,497 - INFO -   Loss: 0.3998
2025-06-20 06:35:55,497 - INFO -   Average similarity: 0.5306
2025-06-20 06:35:55,497 - INFO -   Median similarity: 0.5383
2025-06-20 06:35:55,497 - INFO -   Clean sample similarity: 0.5306
2025-06-20 06:35:55,497 - INFO -   Corrupted sample similarity: 0.3089
2025-06-20 06:35:55,497 - INFO -   Similarity gap (clean - corrupt): 0.2217
2025-06-20 06:35:55,650 - INFO - Epoch 27/30 - Train Loss: 0.0104, Val Loss: 0.3998, Clean Sim: 0.5306, Corrupt Sim: 0.3089, Gap: 0.2217, Time: 7144.44s
2025-06-20 08:17:47,528 - INFO - Epoch 28: Total optimizer steps: 172
2025-06-20 08:35:27,131 - INFO - Validation metrics:
2025-06-20 08:35:27,131 - INFO -   Loss: 0.3939
2025-06-20 08:35:27,131 - INFO -   Average similarity: 0.5320
2025-06-20 08:35:27,131 - INFO -   Median similarity: 0.5389
2025-06-20 08:35:27,131 - INFO -   Clean sample similarity: 0.5320
2025-06-20 08:35:27,132 - INFO -   Corrupted sample similarity: 0.3058
2025-06-20 08:35:27,132 - INFO -   Similarity gap (clean - corrupt): 0.2261
2025-06-20 08:35:27,300 - INFO - Epoch 28/30 - Train Loss: 0.0098, Val Loss: 0.3939, Clean Sim: 0.5320, Corrupt Sim: 0.3058, Gap: 0.2261, Time: 7161.95s
2025-06-20 10:22:48,096 - INFO - Epoch 29: Total optimizer steps: 172
2025-06-20 10:41:02,142 - INFO - Validation metrics:
2025-06-20 10:41:02,142 - INFO -   Loss: 0.3840
2025-06-20 10:41:02,142 - INFO -   Average similarity: 0.5200
2025-06-20 10:41:02,143 - INFO -   Median similarity: 0.5264
2025-06-20 10:41:02,143 - INFO -   Clean sample similarity: 0.5200
2025-06-20 10:41:02,143 - INFO -   Corrupted sample similarity: 0.2894
2025-06-20 10:41:02,143 - INFO -   Similarity gap (clean - corrupt): 0.2306
2025-06-20 10:41:02,293 - INFO - Epoch 29/30 - Train Loss: 0.0098, Val Loss: 0.3840, Clean Sim: 0.5200, Corrupt Sim: 0.2894, Gap: 0.2306, Time: 7524.73s
2025-06-20 12:27:46,504 - INFO - Epoch 30: Total optimizer steps: 172
2025-06-20 12:45:27,938 - INFO - Validation metrics:
2025-06-20 12:45:27,938 - INFO -   Loss: 0.3974
2025-06-20 12:45:27,938 - INFO -   Average similarity: 0.5136
2025-06-20 12:45:27,938 - INFO -   Median similarity: 0.5200
2025-06-20 12:45:27,938 - INFO -   Clean sample similarity: 0.5136
2025-06-20 12:45:27,938 - INFO -   Corrupted sample similarity: 0.2937
2025-06-20 12:45:27,939 - INFO -   Similarity gap (clean - corrupt): 0.2200
2025-06-20 12:45:28,091 - INFO - Epoch 30/30 - Train Loss: 0.0098, Val Loss: 0.3974, Clean Sim: 0.5136, Corrupt Sim: 0.2937, Gap: 0.2200, Time: 7455.43s
2025-06-20 13:02:09,455 - INFO - Training completed!
2025-06-20 13:02:19,416 - INFO - Evaluating best models on test set...
2025-06-20 13:02:25,492 - INFO - Loaded best loss model from epoch 5
2025-06-20 13:21:41,243 - INFO - Test (Best Loss) metrics:
2025-06-20 13:21:41,243 - INFO -   Loss: 0.2519
2025-06-20 13:21:41,244 - INFO -   Average similarity: 0.3359
2025-06-20 13:21:41,244 - INFO -   Median similarity: 0.3482
2025-06-20 13:21:41,244 - INFO -   Clean sample similarity: 0.3359
2025-06-20 13:21:41,244 - INFO -   Corrupted sample similarity: -0.0162
2025-06-20 13:21:41,244 - INFO -   Similarity gap (clean - corrupt): 0.3521
2025-06-20 13:39:44,313 - INFO - Loaded best gap model from epoch 5
2025-06-20 13:58:39,249 - INFO - Test (Best Gap) metrics:
2025-06-20 13:58:39,249 - INFO -   Loss: 0.2471
2025-06-20 13:58:39,250 - INFO -   Average similarity: 0.3359
2025-06-20 13:58:39,250 - INFO -   Median similarity: 0.3482
2025-06-20 13:58:39,250 - INFO -   Clean sample similarity: 0.3359
2025-06-20 13:58:39,250 - INFO -   Corrupted sample similarity: -0.0221
2025-06-20 13:58:39,250 - INFO -   Similarity gap (clean - corrupt): 0.3580
